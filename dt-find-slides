#!/usr/bin/env python3

import cv2
import fire
from dubbing_tools.transcript import *
import sys
import os
# from skimage.measure import compare_ssim as ssim
from skimage.metrics import structural_similarity as ssim
import json
from dataclasses import dataclass, field
from dataclasses_json import dataclass_json
import numpy
import re
import glob
from dubbing_tools.videodata import StillData, VideoData
from typing import Optional


@dataclass
class Frame:
    time: float
    frame: any
    frame_number: int
    image_file: str


def cmd(
        video_file: str = None,
        output_path: str = './slides',
        verbose: bool = True,
        skip: int = 30,
        similarity: float = 0.98,
        # i1 to 4 tells the program to ignore one quarter in comparing still images starting from the top left going CW.
        i1: bool = False,
        i2: bool = False,
        i3: bool = False,
        i4: bool = False,
        # default head, tells the program to compare stills first based on middle upper third in a 3X2 division (where the head normaly would be)
        defhead: bool = True,
        look_behind: int = 2):
    """
    find presentation slides in videos

    This program examines a video to find when a fullscreen slide (still image) is displayed on the screen.
    These images are output to the specified directory as JPEGs along with timings for display of the images
    in JSON format.

    Translated slides can then be overlaid on the video using xref:dt-replace-slides.adoc[`dt-replace-slides`]

    :param video_file: name of the source video file
    :param output_path: directory into which slide images and timings are written.
            If the path does not exist, it is created
    :param verbose: display verbose progress on STDERR
    :param skip: number of frames to skip between checks for movement
    :param similarity: number representing how similar frames should be to be considered a match
            where 1.0 equals a perfect match
    :param look_behind: check if a still image has been previously displayed by checking
            the last `n` still images
    """

    if video_file is None:
        files = glob.glob("*-src.mp4")
        if len(files):
            files.sort()
            video_file = files[0]
        else:
            print('No video source found.', file=sys.stderr)
            exit(1)

    data = VideoData(video_file=video_file)

    def similar(frame1: Frame, frame2: Frame) -> bool:
        height, width, _ = frame1.frame.shape
        mid_height = height // 2
        mid_width = width // 2

        third_width = width // 3
        # first check for default head position similarity
        if defhead:
            top_center1 = frame1.frame[:mid_height, third_width:2*third_width, :]
            top_center2 = frame2.frame[:mid_height, third_width:2*third_width, :]
            if ssim(top_center1, top_center2, channel_axis=2) < similarity:
                return False

        # top left quarter
        if not i1:
            top_left1 = frame1.frame[:mid_height, :mid_width, :]
            top_left2 = frame2.frame[:mid_height, :mid_width, :]
            if ssim(top_left1, top_left2, channel_axis=2) < similarity:
                return False 

        # top right quarter
        if not i2:
            top_right1 = frame1.frame[:mid_height, mid_width:, :]
            top_right2 = frame2.frame[:mid_height, mid_width:, :]
            if ssim(top_right1, top_right2, channel_axis=2) < similarity:
                return False 

        # bottom right quarter
        if not i3:
            bottom_right1 = frame1.frame[mid_height:, mid_width:, :]
            bottom_right2 = frame2.frame[mid_height:, mid_width:, :]
            if ssim(bottom_right1, bottom_right2, channel_axis=2) < similarity:
                return False 

        # bottom left quarter
        if not i4:
            bottom_left1 = frame1.frame[mid_height:, :mid_width, :]
            bottom_left2 = frame2.frame[mid_height:, :mid_width, :]
            if ssim(bottom_left1, bottom_left2, channel_axis=2) < similarity:
                return False 

        return True   

    if not os.path.exists(output_path):
        os.makedirs(output_path)

    capture = cv2.VideoCapture(video_file)

    frame_num = 0
    last_frame = None  # type: Optional[Frame]
    frame_start = None
    frame_end = None
    time_start = None
    time_end = None
    previous = []  # type: list[Frame]
    current = []  # type: list[Frame]
    still_images = []  # type: list[Frame]

    data.write(path=output_path)

    while True:
        success, f = capture.read()
        time = round(capture.get(cv2.CAP_PROP_POS_MSEC)/1000, 2)
        frame_num += 1

        if not success:
            break

        frame = Frame(time, f, frame_num, image_file=None)
        current.append(frame)

        # enter this if every (skip or 30) frmes
        if (frame_num-1) % skip == 0:
            # print(f'Frame: {frame_num}', file=sys.stderr)
            try:
                # in the case of the first major frame
                if last_frame is None:
                    last_frame = frame

                # in case the current major frame is the same as the last major frame (it's a slide)
                elif similar(frame, last_frame):
                    # assume the current major frame is the end of the slide, and set the frame_end of the slide to the current major frame number, and the time_end of the slide to the current major frame time
                    frame_end = frame.frame_number
                    time_end = frame.time

                    # if frame_start is None (meaning this is the second major frame in the slide and it's the first time to notice it's a slide), now calculate the start of the slide
                    if frame_start is None:
                        frame_start = frame.frame_number
                        time_start = frame.time

                        i = None
                        matched = False
                        for j in [32, 16, 8, 4, 2, 1]:
                            if j >= len(previous):
                                continue

                            if i is None:
                                i = j
                            elif matched or i >= len(previous):
                                i -= j
                            else:
                                i += j

                            if 0 <= i < len(previous) and similar(frame, previous[i]):
                                time_start = previous[i].time
                                frame_start = previous[i].frame_number
                                matched = True
                            else:
                                matched = False

                        data.stills.append(
                            StillData(
                                frame_start=frame_start,
                                frame_end=frame_end,
                                time_start=time_start,
                                time_end=time_end,
                            )
                        )

                    # data.last_still.frame_end = frame.frame_number
                    # data.last_still.time_end = frame.time
                
                # in all other cases (meaning the current major frame is NOT the same as the last major frame)
                else:
                    # in case frame start has a value (meaning we did calculate the start of the slide), now calculate the end of the slide
                    if frame_start is not None:  # and frame_end - frame_start >= skip:
                        i = None
                        matched = False
                        for j in [32, 16, 8, 4, 2, 1]:
                            if j >= len(current):
                                continue

                            if i is None:
                                i = j
                            elif matched or i < 0:
                                i += j
                            else:
                                i -= j

                            if 0 <= i < len(current) and similar(last_frame, current[i]):
                                time_end = current[i].time
                                frame_end = current[i].frame_number
                                matched = True
                            else:
                                matched = False

                        # update the last still with the correct frame end and tiem end that were assumed at the start of the frame
                        data.last_still.frame_end = frame_end
                        data.last_still.time_end = time_end

                        # check for similar still
                        image_file = None
                        for i in range(1, (min(len(still_images), look_behind) + 1) ):
                            if similar(last_frame, still_images[-i]):
                                image_file = still_images[-i].image_file
                                break

                        if image_file is None:
                            image_file = f'slide-{str(len(still_images)+1).rjust(3, "0")}.jpg'
                            last_frame.image_file = image_file
                            still_images.append(last_frame)
                        # #########################

                        data.last_still.image_file = image_file
                        cv2.imwrite(os.path.join(output_path, image_file), last_frame.frame)
                        data.write(path=output_path)

                        frame_start = None
                        frame_end = None

            except Exception as exc:
                print(f'Frame number: {frame_num}')
                raise exc

            last_frame = frame
            previous = current
            current = []

            if verbose:
                total_seconds = round(time, 0)
                seconds = total_seconds % 60
                seconds = int(seconds)
                minutes = (total_seconds/60) % 60
                minutes = int(minutes)
                hours = (total_seconds/(60*60)) % 24

                print("\rTime:  %d:%02d:%02d" % (hours, minutes, seconds), file=sys.stderr, end='')
                # print(f'Frame: {frame_num}, {round(time/1000,1)}', file=sys.stderr)

    if verbose:
        print(file=sys.stderr)

    capture.release()


if __name__ == "__main__":
    fire.Fire(cmd)
